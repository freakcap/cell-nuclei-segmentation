{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclie Semantic Segmentation - UNet using Tensorflow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu==2.0.0-alpha0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c332549b-8d23-4bb5-8497-e7a8eb8b21d2",
    "_uuid": "5c38504af3a84bee68c66d3cde74443c58df422f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from PIL import ImageFile\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dropout, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH = './stage1_train/'\n",
    "TEST_PATH = './stage1_test/'\n",
    "FINAL_TEST_PATH = './stage2_test_final/'\n",
    "\n",
    "#TRAIN_PATH = 'data/stage1_train/'\n",
    "#TEST_PATH = 'data/stage1_test/'\n",
    "#FINAL_TEST_PATH = 'data/stage2_test_final/'\n",
    "\n",
    "dir_path = ''\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!unzip ../input/stage1_train.zip -d stage1_train ;unzip ../input/stage1_test.zip -d stage1_test ;unzip ../input/stage2_test_final.zip -d stage2_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ffa0caf0-2d1b-40f2-865b-8e6db88526b6",
    "_uuid": "3fb9d6530fbbd0e22e41fc4fd9fd9fc0bff027ac"
   },
   "outputs": [],
   "source": [
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]\n",
    "final_test_ids = next(os.walk(FINAL_TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "59c4a25d-645f-4b74-9c53-145ac78cc481",
    "_uuid": "875af74f980236825de3a650825b46e25632422c"
   },
   "source": [
    "\n",
    "- Downsampling to reduce computations\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and resize train images and masks\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ca0cc34b-c26f-41ee-88d7-975aebdb634e",
    "_uuid": "9e389ba8bdb5b6fc03b231b6a6c84a8bde634053",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    \n",
    "    #Read image files iteratively\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = imread(dir_path + path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    \n",
    "    #Append image to numpy array for train dataset\n",
    "    X_train[n] = img\n",
    "    \n",
    "    #Read corresponding mask files iteratively\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    \n",
    "    #Looping through masks\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        \n",
    "        #Read individual masks\n",
    "        mask_ = imread(dir_path + path + '/masks/' + mask_file)\n",
    "        \n",
    "        #Expand individual mask dimensions\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        \n",
    "        #Overlay individual masks to create a final mask for corresponding image\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    \n",
    "    #Append mask to numpy array for train dataset\n",
    "    Y_train[n] = mask\n",
    "\n",
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    \n",
    "    #Read images iteratively\n",
    "    img = imread(dir_path + path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    \n",
    "    #Get test size\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    \n",
    "    #Resize image to match training data\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    \n",
    "    #Append image to numpy array for test dataset\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c0523b03-1fc5-4505-a1b8-eb35ee617c8a",
    "_uuid": "d4f8327802a1ec6139ce0585953986272ba62ce1"
   },
   "source": [
    "## Visualize imported data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "88829b53-50ce-45d9-9540-77dd7384ad4c",
    "_uuid": "283af26f0860b7069bdfd133c746e5d20971542c"
   },
   "outputs": [],
   "source": [
    "# Check if training data looks all right\n",
    "ix = random.randint(0, len(train_ids))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = label(y_true_in > 0.5)\n",
    "    y_pred = label(y_pred_in > 0.5)\n",
    "    \n",
    "    true_objects = len(np.unique(labels))\n",
    "    pred_objects = len(np.unique(y_pred))\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.array(np.mean(metric), dtype=np.float32)\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    metric_value = tf.py_func(iou_metric_batch, [label, pred], tf.float32)\n",
    "    return metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c1dbc57c-b497-4ccb-b077-2053203ab7ed",
    "_uuid": "0aa97d66c29f45dfac9b0f45fcf74ba0e778ba5d"
   },
   "outputs": [],
   "source": [
    "# Build U-Net model\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "c1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (s)\n",
    "c1 = BatchNormalization()(c1)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "c1 = BatchNormalization()(c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = BatchNormalization()(c2)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "c2 = BatchNormalization()(c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = BatchNormalization()(c3)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "c3 = BatchNormalization()(c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = BatchNormalization()(c4)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "c4 = BatchNormalization()(c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = BatchNormalization()(c5)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "c5 = BatchNormalization()(c5)\n",
    "\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = BatchNormalization()(c6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "c6 = BatchNormalization()(c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = BatchNormalization()(c7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "c7 = BatchNormalization()(c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = BatchNormalization()(c8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "c8 = BatchNormalization()(c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = BatchNormalization()(c9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "c9 = BatchNormalization()(c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9415b1c4-aa69-41b9-a1e3-d6053dbd4f64",
    "_uuid": "c060db22daa2abf12b28240cd81bbcbf1ce1bf87"
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "earlystopper = EarlyStopping(patience=15, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model_unet_checkpoint.h5', verbose=1, save_best_only=True)\n",
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=100, \n",
    "                    callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1f381f5b-1b71-4daa-a417-e02f4894540b",
    "_uuid": "bb15226ea617cf91ed8f43179fccb5a15809e5a0"
   },
   "source": [
    "\n",
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2daa48d5-ac98-4e18-af3f-a582baaa44f0",
    "_uuid": "f841760b4abca1a25cb750822f88268bd79bf2ce"
   },
   "outputs": [],
   "source": [
    "# Predict on train, val and test\n",
    "model = load_model('model_unet_checkpoint.h5')\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test_t)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test_t[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 21\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(131)\n",
    "imshow(X_train[ix])\n",
    "plt.title(\"Image\")\n",
    "plt.subplot(132)\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.title(\"Mask\")\n",
    "plt.subplot(133)\n",
    "imshow(np.squeeze(preds_train_t[ix] > 0.5))\n",
    "plt.title(\"Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum=0\n",
    "for ix in range(603):\n",
    "    sum = sum + iou_metric(np.squeeze(Y_train[ix]), np.squeeze(preds_train_t[ix]), print_table=True)\n",
    "    \n",
    "print(sum/603)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "649248cd-a1fb-4da6-ade2-4bebad44bcab",
    "_uuid": "7e06242a50870e07a080064a4912b761775990fa"
   },
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random training samples\n",
    "ix = random.randint(0, len(preds_test_t))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_train_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4f66b75c-c694-41a1-8c91-34bb6595837b",
    "_uuid": "d4ccbb559375bc2777ffb692a20adc313159f2cc"
   },
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random validation samples\n",
    "ix = random.randint(0, len(preds_val_t))\n",
    "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_val_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "59a0af60-a7d7-41ef-a6fe-9e3c72defa07",
    "_uuid": "4f99c1bf852e82b60bd4f982ca0df293f712cdf0"
   },
   "outputs": [],
   "source": [
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cutoff=0.5):\n",
    "    lab_img = label(x > cutoff)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "31133f8c-3f40-4dff-8e1d-898d56672332",
    "_uuid": "2e07f6afc4787b068ba714428145dcb3951d718f"
   },
   "source": [
    "- Iterate over the test IDs and generate run-length encodings for each seperate mask identified by skimage ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "22fe24a1-7659-4cc9-9d23-211f38e5b99f",
    "_uuid": "089587843ed6a3955fdcb9b23a6ec3bf5d703688"
   },
   "outputs": [],
   "source": [
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_] * len(rle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "20b6b627-0fd6-425d-888f-da7f39efb124",
    "_uuid": "849184a40a2c9c21506d8b8eb10ad9155fa229e8"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1ba0ee3a-cca0-4349-83f6-09a1ac6fcb44",
    "_uuid": "ba589f56f5be1e6886bc88f5bf9e7d0a408e4048"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
